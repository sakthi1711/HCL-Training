{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q autocorrect"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iySxjio6Tmy",
        "outputId": "d55d5c53-5ccb-462f-d076-6ee2d7ba5430"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/622.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m622.8/622.8 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for autocorrect (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsA2iVpg5rKq",
        "outputId": "a6cb8b61-6a79-4a71-90b4-7d38155fcfe3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The car is a powerfl symbol of fredom, connecting us to distant places and new experiences. It reshaped cities, turning high streets into avenues lined with drive-thrus and parking lots. More than metal and ruber, it’s a private space where we spend countless hours of our lives.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from autocorrect import Speller\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "\n",
        "f = open('/content/car.txt')\n",
        "raw = f.read()\n",
        "print(raw)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "words = word_tokenize(raw)\n",
        "print(f\"Initial 30 tokens: {words[:30]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bG0V9t56cMK",
        "outputId": "79ded803-7b9c-47dc-c248-c581381375a9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial 30 tokens: ['The', 'car', 'is', 'a', 'powerfl', 'symbol', 'of', 'fredom', ',', 'connecting', 'us', 'to', 'distant', 'places', 'and', 'new', 'experiences', '.', 'It', 'reshaped', 'cities', ',', 'turning', 'high', 'streets', 'into', 'avenues', 'lined', 'with', 'drive-thrus']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spell_checker = Speller()\n",
        "corrected_tokens = [spell_checker(word) for word in words]\n",
        "print(f\"Initial 10 corrected tokens: {corrected_tokens[:10]}\")\n",
        "\n",
        "corrected_text_corpus = ' '.join(corrected_tokens)\n",
        "print(f\"Corrected text corpus snippet (first 100 characters): {corrected_text_corpus[:100]}...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhn09rHb7dDt",
        "outputId": "5878c94a-a178-4cbf-be2a-a929568e2ecc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial 10 corrected tokens: ['The', 'car', 'is', 'a', 'powerful', 'symbol', 'of', 'freedom', ',', 'connecting']\n",
            "Corrected text corpus snippet (first 100 characters): The car is a powerful symbol of freedom , connecting us to distant places and new experiences . It s...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "pos_tagged_tokens = nltk.pos_tag(corrected_tokens)\n",
        "print(f\"POS tagged corrected tokens (initial 10): {pos_tagged_tokens[:10]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHm6SL_l9BC6",
        "outputId": "5b4f194d-da6a-488a-c472-137ae98dfa77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "POS tagged corrected tokens (initial 10): [('Sivakasi', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('major', 'JJ'), ('industrial', 'JJ'), ('city', 'NN'), ('in', 'IN'), ('Virudhunagar', 'NNP'), ('district', 'NN'), ('of', 'IN')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords') # Download 'stopwords' if needed [cite: 128]\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "filtered_tokens = [w for w in corrected_tokens if w.lower() not in stop_words]\n",
        "print(f\"Filtered tokens (initial 20, after stop word removal): {filtered_tokens[:20]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPwVrWis9xVt",
        "outputId": "455156e3-80f6-412c-8fae-a47ca3b841ec"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered tokens (initial 20, after stop word removal): ['car', 'powerful', 'symbol', 'freedom', ',', 'connecting', 'us', 'distant', 'places', 'new', 'experiences', '.', 'shaped', 'cities', ',', 'turning', 'high', 'streets', 'avenues', 'lined']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p_stemmer = PorterStemmer()\n",
        "stemmed_tokens = [p_stemmer.stem(w) for w in filtered_tokens]\n",
        "print(f\"Stemmed tokens (initial 20): {stemmed_tokens[:20]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akIzYHGx-oxA",
        "outputId": "bd8de26c-f2fb-4128-b89c-7bb6413a6100"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stemmed tokens (initial 20): ['car', 'power', 'symbol', 'freedom', ',', 'connect', 'us', 'distant', 'place', 'new', 'experi', '.', 'shape', 'citi', ',', 'turn', 'high', 'street', 'avenu', 'line']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_tokens = [lemmatizer.lemmatize(w) for w in filtered_tokens]\n",
        "print(f\"Lemmatized tokens (initial 20): {lemmatized_tokens[:20]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLJvFA4sCyQh",
        "outputId": "3a6238bf-b4bf-4805-e256-e9dc2285041b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemmatized tokens (initial 20): ['car', 'powerful', 'symbol', 'freedom', ',', 'connecting', 'u', 'distant', 'place', 'new', 'experience', '.', 'shaped', 'city', ',', 'turning', 'high', 'street', 'avenue', 'lined']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = sent_tokenize(raw)\n",
        "total_sentences = len(sentences)\n",
        "print(f\"Total number of sentences detected in the text corpus: {total_sentences}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUvaGrC9DTGW",
        "outputId": "5bee1e19-9031-4873-b7d5-e43bc321b7ec"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of sentences detected in the text corpus: 3\n"
          ]
        }
      ]
    }
  ]
}